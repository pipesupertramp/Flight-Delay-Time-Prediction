{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing, libraries, and formating:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import pickle\r\n",
    "# import scipy.stats as st\r\n",
    "# import plotly.express as px\r\n",
    "\r\n",
    "#stats\r\n",
    "import statsmodels.api as sm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "# importing and basic formating\r\n",
    "flights = pd.read_csv('C:/Users/danfv/OneDrive/Knowledge/Courses/Data Analysis/LHL - Data Analysis Bootcamp/lighthouse-data-notes/W6 Midterm Project/Midterm_Project/Data/Flights - Sample 50000 - Added Dan Features.csv').sort_values('fl_date').reset_index(drop=True)\r\n",
    "flights = flights.drop('Unnamed: 0', axis=1)\r\n",
    "\r\n",
    "# deleting features the model won't use\r\n",
    "drop_engineered_dan = ['fl_date', 'month', 'crs_dep_time', 'crs_arr_time', 'mkt_unique_carrier', 'branded_code_share',\r\n",
    "    'mkt_carrier', 'mkt_carrier_fl_num', 'op_unique_carrier', 'op_carrier_fl_num']\r\n",
    "drop_engineered_peter = ['dest', 'dest_airport_id', 'dest_city_name', 'origin', 'origin_airport_id', 'origin_city_name']\r\n",
    "drop_streamlining = ['dup', 'flights', 'tail_num']\r\n",
    "original_remain = ['crs_elapsed_time', 'distance']\r\n",
    "\r\n",
    "initial_drop = drop_engineered_dan + drop_engineered_peter + drop_streamlining\r\n",
    "flights = flights.drop(initial_drop, axis=1)\r\n",
    "\r\n",
    "# renaming target\r\n",
    "flights = flights.rename(columns={'total_delay' : 'arr_delay'})\r\n",
    "\r\n",
    "# Separating features and target for regression:\r\n",
    "X = flights.drop('arr_delay', axis=1)\r\n",
    "y = flights.arr_delay\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining Function to run linear regressions:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "from sklearn.metrics import r2_score\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.metrics import mean_absolute_error\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from sklearn.compose import TransformedTargetRegressor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "regressor_list = ['LinearRegression()', 'RandomForestRegressor()']\r\n",
    "func_list = ['None', 'np.log']\r\n",
    "inverse_func_list = ['None', 'np.exp']\r\n",
    "\r\n",
    "def trans_tar_reg_function(X, y, regressor, func, inverse_func):\r\n",
    "    '''\r\n",
    "    Generates R2, RMSE and MAE of models using the specified regressor, function and inverse_func for y\r\n",
    "    Parameters:\r\n",
    "    - X = features df\r\n",
    "    - y = target df\r\n",
    "    - regressor = method/algo to do the regression\r\n",
    "    - func = transformation of y\r\n",
    "    - inverse_fun = to get transformed y back to original units\r\n",
    "    '''\r\n",
    "\r\n",
    "    #instantiating the target regressor\r\n",
    "    ttr = TransformedTargetRegressor(regressor=regressor, func=func, inverse_func=inverse_func)\r\n",
    "    # fitting \r\n",
    "    ttr.fit(X, y)\r\n",
    "    # Model Evaluation\r\n",
    "    y_pred = ttr.predict(X)\r\n",
    "    n = y.shape[0]\r\n",
    "    p = X.shape[1]\r\n",
    "    R2_adj = 1-(1-r2_score(y, y_pred))*(n-1)/(n-p-1)\r\n",
    "    RMSE = mean_squared_error(y, y_pred)\r\n",
    "    MAE = mean_absolute_error(y, y_pred)\r\n",
    "\r\n",
    "    return [R2_adj, RMSE, MAE]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Combinations of different features and scaling:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "# original X:\r\n",
    "X\r\n",
    "\r\n",
    "# Removing features with p-value > 0.05 when fitting with X (prob. weight = 0 is statistically significant):\r\n",
    "X_pval_filter = X.drop(['Season', 'Weekday', 'dest_airp_fl_ind',\r\n",
    "       'orig_airp_pss_ind', 'orig_airp_pss_ind', 'dest_airp_pss_ind'], axis=1)\r\n",
    "\r\n",
    "# adding 1 to zero values in y (flights with no delays):\r\n",
    "y_plus1 = y + 1\r\n",
    "\r\n",
    "# standardized time and distance:\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "#new df with standardized values\r\n",
    "X_stscaled = X.copy()\r\n",
    "# features to standardize\r\n",
    "stand_feat = ['crs_elapsed_time', 'distance']\r\n",
    "# adding the standardized columns\r\n",
    "standardized_feat = StandardScaler().fit_transform(X_stscaled[stand_feat])\r\n",
    "X_stscaled['crs_elap_t_std'], X_stscaled['dist_std'] = [standardized_feat[:,0], standardized_feat[:,1]]\r\n",
    "# dropping the original values\r\n",
    "X_stscaled = X_stscaled.drop(['crs_elapsed_time', 'distance'], axis=1)\r\n",
    "\r\n",
    "# dropping features with high correlations in correlation matrix X vs y:\r\n",
    "X_correl_filter = X.drop(['distance', 'orig_airp_pss_ind', 'dest_airp_pss_ind'], axis=1)\r\n",
    "\r\n",
    "# dropping features with high correlations in correlation matrix X_stscaled vs y:\r\n",
    "X_stscaled_correl_filter = X_stscaled.drop(['dist_std', 'orig_airp_pss_ind', 'dest_airp_pss_ind'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adding iterations to df:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "# Creating empty df to store metrics and compare:\r\n",
    "\r\n",
    "# lr_metrics_df = pd.DataFrame(columns=['R2_adj', 'RMSE', 'MAE'], dtype='float64')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "trans_tar_reg_function(X_stscaled_correl_filter, y_plus1, LinearRegression(), np.log, np.exp)\r\n",
    "# trans_tar_reg_function(X_correl_filter, y, LinearRegression(), None, None)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-0.05981474200934778, 2505.5137068687986, 13.791662512853026]"
      ]
     },
     "metadata": {},
     "execution_count": 199
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "source": [
    "lr_metrics_df.loc['X_stscaled_correl_filter / y_plus1'] = trans_tar_reg_function(X_stscaled_correl_filter, y_plus1, LinearRegression(), np.log, np.exp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "lr_metrics_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2_adj</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X / y</th>\n",
       "      <td>0.008623</td>\n",
       "      <td>2343.579124</td>\n",
       "      <td>20.949733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_pval_filter / y</th>\n",
       "      <td>0.008585</td>\n",
       "      <td>2343.903082</td>\n",
       "      <td>20.955273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X / y_plus1</th>\n",
       "      <td>-0.059841</td>\n",
       "      <td>2505.424457</td>\n",
       "      <td>13.791379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_stscaled / y_plus1</th>\n",
       "      <td>-0.059841</td>\n",
       "      <td>2505.424457</td>\n",
       "      <td>13.791379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_correl_filter / y</th>\n",
       "      <td>0.008459</td>\n",
       "      <td>2344.108511</td>\n",
       "      <td>20.955721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_correl_filter / y_plus1</th>\n",
       "      <td>-0.059815</td>\n",
       "      <td>2505.513707</td>\n",
       "      <td>13.791663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_stscaled_correl_filter / y_plus1</th>\n",
       "      <td>-0.059815</td>\n",
       "      <td>2505.513707</td>\n",
       "      <td>13.791663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      R2_adj         RMSE        MAE\n",
       "X / y                               0.008623  2343.579124  20.949733\n",
       "X_pval_filter / y                   0.008585  2343.903082  20.955273\n",
       "X / y_plus1                        -0.059841  2505.424457  13.791379\n",
       "X_stscaled / y_plus1               -0.059841  2505.424457  13.791379\n",
       "X_correl_filter / y                 0.008459  2344.108511  20.955721\n",
       "X_correl_filter / y_plus1          -0.059815  2505.513707  13.791663\n",
       "X_stscaled_correl_filter / y_plus1 -0.059815  2505.513707  13.791663"
      ]
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Vanilla Baseline Model:\r\n",
    "- No feature scaling\r\n",
    "- No removal of correlated features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All features:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# adding a constant for X\r\n",
    "X_all = sm.add_constant(X)\r\n",
    "\r\n",
    "#modeling vanilla ls\r\n",
    "model = sm.OLS(y, X_all).fit()\r\n",
    "# pickle.dump(model, open('Data/Pickles/vanilla_ls_allfeat_noscalling.sav', 'wb'))\r\n",
    "print(model.summary())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              arr_delay   R-squared:                       0.009\n",
      "Model:                            OLS   Adj. R-squared:                  0.009\n",
      "Method:                 Least Squares   F-statistic:                     34.45\n",
      "Date:                Wed, 22 Sep 2021   Prob (F-statistic):           4.28e-87\n",
      "Time:                        17:25:55   Log-Likelihood:            -2.6493e+05\n",
      "No. Observations:               50000   AIC:                         5.299e+05\n",
      "Df Residuals:                   49986   BIC:                         5.300e+05\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     9.5556      2.141      4.464      0.000       5.360      13.751\n",
      "crs_elapsed_time          0.0640      0.018      3.657      0.000       0.030       0.098\n",
      "distance                 -0.0064      0.002     -3.035      0.002      -0.011      -0.002\n",
      "Season                   -0.3566      0.197     -1.808      0.071      -0.743       0.030\n",
      "Weekday                   0.0274      0.108      0.253      0.800      -0.185       0.240\n",
      "peak_season               2.0090      0.270      7.451      0.000       1.481       2.538\n",
      "dep_taxi_ind            180.6542     27.841      6.489      0.000     126.086     235.223\n",
      "arr_taxi_ind           -245.9767     19.573    -12.567      0.000    -284.341    -207.613\n",
      "carriers_lateness_ind    96.1982      7.265     13.242      0.000      81.959     110.437\n",
      "airtime_ind               9.1905      3.310      2.777      0.005       2.703      15.678\n",
      "orig_airp_fl_ind        -11.0587     47.998     -0.230      0.818    -105.135      83.017\n",
      "dest_airp_fl_ind        -39.4000     47.901     -0.823      0.411    -133.286      54.486\n",
      "orig_airp_pss_ind       -41.4932     61.763     -0.672      0.502    -162.550      79.563\n",
      "dest_airp_pss_ind        79.6172     61.372      1.297      0.195     -40.673     199.907\n",
      "==============================================================================\n",
      "Omnibus:                    84150.558   Durbin-Watson:                   1.974\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        132245873.067\n",
      "Skew:                          11.311   Prob(JB):                         0.00\n",
      "Kurtosis:                     253.931   Cond. No.                     3.56e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.56e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Model Evaluation\r\n",
    "y_pred = model.predict(X_all)\r\n",
    "n = y.shape[0]\r\n",
    "p = X_all.shape[1]\r\n",
    "print('R2 (adj) =', 1-(1-r2_score(y, y_pred))*(n-1)/(n-p-1))\r\n",
    "print('RMSE =', mean_squared_error(y, y_pred))\r\n",
    "print('MAE =', mean_absolute_error(y, y_pred))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 (adj) = 0.008603122510426053\n",
      "RMSE = 2343.579124388721\n",
      "MAE = 20.949733276135145\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Removing features with p-value > 0.05 (prob. weight = 0 is statistically significant):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# adding a constant for X\r\n",
    "X_pval_filter = X_all.drop(['Season', 'Weekday', 'dest_airp_fl_ind',\r\n",
    "       'orig_airp_pss_ind', 'orig_airp_pss_ind', 'dest_airp_pss_ind'], axis=1)\r\n",
    "\r\n",
    "#modeling vanilla ls\r\n",
    "model = sm.OLS(y, X_pval_filter).fit()\r\n",
    "print(model.summary())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              arr_delay   R-squared:                       0.009\n",
      "Model:                            OLS   Adj. R-squared:                  0.009\n",
      "Method:                 Least Squares   F-statistic:                     55.12\n",
      "Date:                Wed, 22 Sep 2021   Prob (F-statistic):           8.18e-90\n",
      "Time:                        17:38:08   Log-Likelihood:            -2.6494e+05\n",
      "No. Observations:               50000   AIC:                         5.299e+05\n",
      "Df Residuals:                   49991   BIC:                         5.300e+05\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     8.9863      2.040      4.404      0.000       4.987      12.986\n",
      "crs_elapsed_time          0.0710      0.017      4.201      0.000       0.038       0.104\n",
      "distance                 -0.0072      0.002     -3.467      0.001      -0.011      -0.003\n",
      "peak_season               2.0200      0.270      7.494      0.000       1.492       2.548\n",
      "dep_taxi_ind            175.6924     27.701      6.343      0.000     121.399     229.986\n",
      "arr_taxi_ind           -243.0581     19.457    -12.492      0.000    -281.193    -204.923\n",
      "carriers_lateness_ind    97.3691      6.937     14.036      0.000      83.773     110.965\n",
      "airtime_ind               9.2866      3.304      2.810      0.005       2.810      15.763\n",
      "orig_airp_fl_ind        -49.3431     15.080     -3.272      0.001     -78.901     -19.785\n",
      "==============================================================================\n",
      "Omnibus:                    84152.390   Durbin-Watson:                   1.973\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        132205087.178\n",
      "Skew:                          11.312   Prob(JB):                         0.00\n",
      "Kurtosis:                     253.892   Cond. No.                     1.33e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.33e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Model Evaluation\r\n",
    "y_pred = model.predict(X_pval_filter)\r\n",
    "n = y.shape[0]\r\n",
    "p = X_pval_filter.shape[1]\r\n",
    "print('R2 (adj) =', 1-(1-r2_score(y, y_pred))*(n-1)/(n-p-1))\r\n",
    "print('RMSE =', mean_squared_error(y, y_pred))\r\n",
    "print('MAE =', mean_absolute_error(y, y_pred))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 (adj) = 0.008565253114060645\n",
      "RMSE = 2343.9030816633085\n",
      "MAE = 20.955272884479278\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Vanilla now Scaled (features and/or target)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Keeping all Features:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With original features:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.compose import TransformedTargetRegressor\r\n",
    "# from sklearn.ensemble import RandomForestRegressor # TRY LATER CHANGING THE REGRESSOR PARAM BELOW\r\n",
    "\r\n",
    "#instantiating the target regressor\r\n",
    "ttr_lr = TransformedTargetRegressor(regressor=LinearRegression(), func=np.log, inverse_func=np.exp)\r\n",
    "# adding 1 to zero values in y (flights with no delays)\r\n",
    "y_plus1 = y + 1\r\n",
    "# fitting \r\n",
    "ttr_lr.fit(X_all, y_plus1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformedTargetRegressor(regressor=LinearRegression())"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# Model Evaluation\r\n",
    "y_pred = ttr_lr.predict(X_all)\r\n",
    "n = y.shape[0]\r\n",
    "p = X_all.shape[1]\r\n",
    "print('R2 (adj) =', 1-(1-r2_score(y, y_pred))*(n-1)/(n-p-1))\r\n",
    "print('RMSE =', mean_squared_error(y, y_pred))\r\n",
    "print('MAE =', mean_absolute_error(y, y_pred))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 (adj) = 0.008603122510426053\n",
      "RMSE = 2343.579124388721\n",
      "MAE = 20.949733276135145\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Standardizing features:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "#new df with standardized values\r\n",
    "X_stscaled = X_all.copy()\r\n",
    "# features to standardize\r\n",
    "stand_feat = ['crs_elapsed_time', 'distance']\r\n",
    "# adding the standardized columns\r\n",
    "standardized_feat = StandardScaler().fit_transform(X_stscaled[stand_feat])\r\n",
    "X_stscaled['crs_elap_t_std'], X_stscaled['dist_std'] = [standardized_feat[:,0], standardized_feat[:,1]]\r\n",
    "# dropping the original values\r\n",
    "# vanilla_std = flights.drop(['crs_elapsed_time', 'distance'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "#instantiating the target regressor\r\n",
    "ttr_lr_Xstd = TransformedTargetRegressor(regressor=LinearRegression(), func=np.log, inverse_func=np.exp)\r\n",
    "# fitting \r\n",
    "ttr_lr_Xstd.fit(X_stscaled, y_plus1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformedTargetRegressor(func=<ufunc 'log'>, inverse_func=<ufunc 'exp'>,\n",
       "                           regressor=LinearRegression())"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature selection: correlation and low variance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Removing redundant correlated features:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# dropping correlated features\r\n",
    "X_correl_filter = X_all.drop(['Season', 'Weekday', 'dest_airp_fl_ind',\r\n",
    "       'orig_airp_pss_ind', 'orig_airp_pss_ind', 'dest_airp_pss_ind'], axis=1)\r\n",
    "\r\n",
    "#modeling vanilla ls\r\n",
    "model = sm.OLS(y, X_pval_filter).fit()\r\n",
    "print(model.summary())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              arr_delay   R-squared:                       0.009\n",
      "Model:                            OLS   Adj. R-squared:                  0.009\n",
      "Method:                 Least Squares   F-statistic:                     55.12\n",
      "Date:                Wed, 22 Sep 2021   Prob (F-statistic):           8.18e-90\n",
      "Time:                        17:38:08   Log-Likelihood:            -2.6494e+05\n",
      "No. Observations:               50000   AIC:                         5.299e+05\n",
      "Df Residuals:                   49991   BIC:                         5.300e+05\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     8.9863      2.040      4.404      0.000       4.987      12.986\n",
      "crs_elapsed_time          0.0710      0.017      4.201      0.000       0.038       0.104\n",
      "distance                 -0.0072      0.002     -3.467      0.001      -0.011      -0.003\n",
      "peak_season               2.0200      0.270      7.494      0.000       1.492       2.548\n",
      "dep_taxi_ind            175.6924     27.701      6.343      0.000     121.399     229.986\n",
      "arr_taxi_ind           -243.0581     19.457    -12.492      0.000    -281.193    -204.923\n",
      "carriers_lateness_ind    97.3691      6.937     14.036      0.000      83.773     110.965\n",
      "airtime_ind               9.2866      3.304      2.810      0.005       2.810      15.763\n",
      "orig_airp_fl_ind        -49.3431     15.080     -3.272      0.001     -78.901     -19.785\n",
      "==============================================================================\n",
      "Omnibus:                    84152.390   Durbin-Watson:                   1.973\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        132205087.178\n",
      "Skew:                          11.312   Prob(JB):                         0.00\n",
      "Kurtosis:                     253.892   Cond. No.                     1.33e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.33e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "y_pred = model.predict(X_pval_filter)\r\n",
    "n = y.shape[0]\r\n",
    "p = X_pval_filter.shape[1]\r\n",
    "print('R2 (adj) =', 1-(1-r2_score(y, y_pred))*(n-1)/(n-p-1))\r\n",
    "print('RMSE =', mean_squared_error(y, y_pred))\r\n",
    "print('MAE =', mean_absolute_error(y, y_pred))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 (adj) = 0.008565253114060645\n",
      "RMSE = 2343.9030816633085\n",
      "MAE = 20.955272884479278\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest Trial:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "# STANDARDIZING TARGET\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from sklearn.datasets import make_regression\r\n",
    "\r\n",
    "X, y = make_regression(n_features=4, n_informative=2,\r\n",
    "                       random_state=0, shuffle=False)\r\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\r\n",
    "regr.fit(X, y)\r\n",
    "\r\n",
    "print(regr.predict([[0, 0, 0, 0]]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-8.32987858]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# Model Evaluation\r\n",
    "y_pred = ttr_lr_Xstd.predict(X_stscaled)\r\n",
    "n = y.shape[0]\r\n",
    "p = X_all.shape[1]\r\n",
    "print('R2 (adj) =', 1-(1-r2_score(y, y_pred))*(n-1)/(n-p-1))\r\n",
    "print('RMSE =', mean_squared_error(y, y_pred))\r\n",
    "print('MAE =', mean_absolute_error(y, y_pred))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 (adj) = -0.050123215299576085\n",
      "RMSE = 2482.403264819574\n",
      "MAE = 14.41152395754018\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "c18c6b22b1b4309ffcbcb5849d3d93ee0df54905d4974277fdd5eccbda2dda89"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}